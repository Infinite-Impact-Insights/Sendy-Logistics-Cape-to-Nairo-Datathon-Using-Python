{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "We_are_the_best.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JOSEPHINEGEND/Sendy-Logistics-Cape-to-Nairo-Datathon/blob/master/We_are_the_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qe6aFGUEFDX",
        "colab_type": "text"
      },
      "source": [
        "### R Insights\n",
        "- CRISP-DM\n",
        "    - Business Understanding\n",
        "    - Data Understanding\n",
        "    - Data Preparation\n",
        "    - Modelling\n",
        "    - Deployment\n",
        "    \n",
        "### Research Question\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Predict the time for delivery\n",
        "\n",
        "### Libraries to use\n",
        " - pacman\n",
        " - tidyverse\n",
        " - caret\n",
        " - skimr\n",
        " \n",
        "### Data Cleaning\n",
        " - Rename columns - Using the gsub function\n",
        " - Remove white  spaces\n",
        " - Encoding categorical variables\n",
        "   - Check for distribution of categorical variables\n",
        "   - \n",
        " \n",
        "### Feature Wngineering\n",
        " - Data accuracy\n",
        " - Create features from time\n",
        " - Distribution of the target variable\n",
        " - Normalise the data\n",
        " - Check for anomalies\n",
        "   - Missing data\n",
        "     - Precipitation and Temperature \n",
        "     - Can impute using\n",
        "      - Mean\n",
        "   - Outliers\n",
        "     - Impute\n",
        "     - Drop\n",
        "     - Create a new column with True False to reflect whether there was an outlier\n",
        "   - Skewed distributions\n",
        "     - Investigate the zero delivery time\n",
        "     - Set a threshold of two minutes or more\n",
        " - Check for measures of measures of central tendacy\n",
        "  - Normalise variables\n",
        "  \n",
        "### Bivariate analysis\n",
        " - Temperature and distance have a postive relationship\n",
        " #### Variable Selction\n",
        " **\n",
        " \n",
        "### Modelling\n",
        " - Bias and variance tradeoff\n",
        " - Shuffle the data\n",
        " - Create train, test and validation sets\n",
        " - Regression models\n",
        " \n",
        "### Cross-validation\n",
        " - compare crossval errors with submission\n",
        " \n",
        "### Parameter tuning\n",
        " - Randomsearch\n",
        " - Gridsearch\n",
        " \n",
        "### Metrics of Success\n",
        " - RME - Most common\n",
        " - MAE - Robust with data that has outliers\n",
        " #### Try different models and compare the rmse's\n",
        " \n",
        "## Python Insights\n",
        " - Hacking\n",
        "  - MLXNET\n",
        "  - Blending\n",
        "  - mirror/mean encoding\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTHRZ671znAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import requests\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from io import StringIO\n",
        "import lightgbm as lgb\n",
        "import lightgbm as lgbb\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "import hyperopt\n",
        "import datetime\n",
        "import datetime as dt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHtOKBtEWsRG",
        "colab_type": "code",
        "outputId": "76e5ee03-b6ad-4b14-dc6f-2c5ef7d74db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/14/35b211f9b1c779faba8061b696760f6da743a15d7b215cd6babb211ced0c/catboost-0.18-cp36-none-manylinux1_x86_64.whl (62.9MB)\n",
            "\u001b[K     |████████████████████████████████| 62.9MB 114kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.3.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.4.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW9IPm8XWzNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZTlKrrlzm9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = 'https://drive.google.com/file/d/1ZP9pFBATu38l97Tut5hKLvpzKRLFXX_P/view?usp=sharing'\n",
        "test = 'https://drive.google.com/file/d/1_aElMoEIRs55avOafA7U1_YXEuaDBXLh/view?usp=sharing'\n",
        "submission = 'https://drive.google.com/file/d/1mqXS8euMqF9_bhTEU6O9cLHoX2FI_5HD/view?usp=sharing'\n",
        "dictionary = 'https://drive.google.com/file/d/1juqltwSs6OXQgJJEhTxD7Gm443fnLpCp/view?usp=sharing'\n",
        "riders = 'https://drive.google.com/file/d/19-aVgAcKRxX_Tk9StUQMNeAUVi0ZTo9K/view?usp=sharing'\n",
        "\n",
        "def read_csv(url):\n",
        "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
        "  csv_raw = requests.get(url).text\n",
        "  csv = StringIO(csv_raw)\n",
        "  return csv\n",
        "\n",
        "train = pd.read_csv(read_csv(train))\n",
        "tes = pd.read_csv(read_csv(test))\n",
        "sub = pd.read_csv(read_csv(submission))\n",
        "dictionary = pd.read_csv(read_csv(dictionary))\n",
        "riders = pd.read_csv(read_csv(riders))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM_S0--VaHXW",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning column names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVcpphrdg8pK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = train.copy()\n",
        "test = tes.copy()\n",
        "y = train[['User Id', 'Time from Pickup to Arrival']]\n",
        "df, test = df.align(test, join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('-', '_').str.replace('=', '_')\n",
        "df.columns = df.columns.str.replace('__', '_')\n",
        "df.columns = df.columns.str.replace('(', '').str.replace(')', '')\n",
        "df.columns = df.columns.str.replace('__', '_')\n",
        "\n",
        "test.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('-', '_').str.replace('=', '_')\n",
        "test.columns = df.columns.str.replace('__', '_')\n",
        "test.columns = df.columns.str.replace('(', '').str.replace(')', '')\n",
        "test.columns = df.columns.str.replace('__', '_')\n",
        "\n",
        "df['separator'] = 1\n",
        "test['separator'] = 0\n",
        "\n",
        "tt = pd.concat([df, test])\n",
        "\n",
        "riders.columns = riders.columns.str.lower().str.replace(' ', '_')\n",
        "comb = tt.merge(riders, how = 'left', on = 'rider_id')\n",
        "\n",
        "#Stripping the order no to have whole numbers\n",
        "comb['order_no']= comb['order_no'].str.replace('Order_No_', '')\n",
        "comb['order_no']=comb['order_no'].astype(int)\n",
        "comb.sort_values(by=['order_no'], ascending= True)\n",
        "\n",
        "\n",
        "comb['temp'] = comb['temperature'].apply(lambda x: True if x == np.nan else False)\n",
        "#Forward Fill Temprature Column\n",
        "comb['temperature'].fillna(df.temperature.mean(), inplace= True)\n",
        "\n",
        "#Backward Fill Temprature column\n",
        "#comb['temperature'].fillna(method='bfill', inplace= True)\n",
        "\n",
        "#Filling in the Precipitation column with 0\n",
        "comb['precipitation_in_millimeters'].fillna(0, inplace= True)\n",
        "\n",
        "time_cols = ['placement_time', 'confirmation_time', 'pickup_time', 'arrival_at_pickup_time']\n",
        "for col in time_cols:\n",
        "  comb[col] = pd.to_datetime(comb[col])\n",
        "  comb[col.split('_')[0] + '_hour'] = comb[col].dt.hour\n",
        "  #comb[col.split('_')[0] + '_minute'] = comb[col].dt.minute\n",
        "  #comb[col] = pd.to_datetime(comb[col], format = '%H:%M:%S', errors = 'coerce')\n",
        "  #comb[col] = [time.time() for time in comb[col]]\n",
        "  \n",
        "  \n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters = 15, init ='k-means++')\n",
        "kmeans.fit(comb[['pickup_lat', 'pickup_long']]) # Compute k-means clustering.\n",
        "comb['pickup_cluster_label'] = kmeans.fit_predict(comb[['pickup_lat', 'pickup_long']])\n",
        "centers1 = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
        "labels1 = kmeans.predict(comb[['pickup_lat', 'pickup_long']]) # Labels of each point\n",
        "comb['pickup_cluster_label'] = comb['pickup_cluster_label'].astype('category')\n",
        "#comb = comb.drop(columns=['pickup_lat', 'pickup_long'])\n",
        "kmeans = KMeans(n_clusters = 15, init ='k-means++')\n",
        "kmeans.fit(comb[['destination_lat', 'destination_long']]) # Compute k-means clustering.\n",
        "comb['destination_cluster_label'] = kmeans.fit_predict(comb[['destination_lat', 'destination_long']])\n",
        "centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
        "labels = kmeans.predict(comb[['destination_lat', 'destination_long']]) # Labels of each point\n",
        "comb['destination_cluster_label'] =comb['destination_cluster_label'].astype('category')\n",
        "#comb = comb.drop(columns=['destination_lat', 'destination_long'])\n",
        "\n",
        "\n",
        "#Peak offpeak 7 - 10 or 4 - 8\n",
        "hour_cols = ['placement_hour',\t'confirmation_hour',\t'pickup_hour', 'arrival_hour']\n",
        "for col in hour_cols:\n",
        "  comb[col.split('_')[0] + '_peak'] = comb[col].apply(lambda x: 1 if ((x >= 7) & (x <= 9)) | ((x >= 16) & (x <= 19)) else 0)\n",
        "  \n",
        "time_cols = ['placement_time', 'confirmation_time', 'pickup_time']\n",
        "for col in time_cols:\n",
        "  comb['arrival_minus_' + col.split('_')[0]] = (comb.arrival_at_pickup_time - comb[col]).astype('timedelta64[s]')\n",
        "  \n",
        "time_cols = ['placement_time', 'confirmation_time']\n",
        "for col in time_cols:\n",
        "  comb['pickup_minus_' + col.split('_')[0]] = (comb.pickup_time - comb[col]).astype('timedelta64[s]')\n",
        "  \n",
        "comb['confir_minus_placement'] = (comb.confirmation_time - comb.placement_time).astype('timedelta64[s]')\n",
        "\n",
        "cat_cols = ['platform_type', 'personal_or_business', 'placement_day_of_month',\n",
        "       'placement_weekday_mo_1', 'placement_hour',\n",
        "       'confirmation_hour', 'pickup_hour', 'arrival_hour',\n",
        "       'pickup_cluster_label', 'destination_cluster_label', 'placement_peak',\n",
        "       'confirmation_peak', 'pickup_peak', 'arrival_peak']\n",
        "\n",
        "for col in cat_cols:\n",
        "  comb[col] = comb[col].astype('category')\n",
        "\n",
        "cols_drop = ['order_no', 'user_id', 'vehicle_type', 'placement_time', 'confirmation_day_of_month',\n",
        "       'confirmation_weekday_mo_1', 'confirmation_time',\n",
        "       'arrival_at_pickup_day_of_month', 'arrival_at_pickup_weekday_mo_1',\n",
        "       'arrival_at_pickup_time', 'pickup_day_of_month', 'pickup_weekday_mo_1',\n",
        "       'pickup_time', 'rider_id']\n",
        "\n",
        "\n",
        "comb.drop(cols_drop, axis = 1, inplace = True)\n",
        "\n",
        "train = comb[comb.separator == 1]\n",
        "test = comb[comb.separator == 0]\n",
        "\n",
        "train.drop('separator', axis = 1, inplace = True)\n",
        "test.drop('separator', axis = 1, inplace = True)\n",
        "\n",
        "train['y'] = y['Time from Pickup to Arrival']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqIOCfDQk5xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tra = train.copy()\n",
        "tes = test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAPk7AJeYUOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = tra.y\n",
        "tra = pd.get_dummies(tra)\n",
        "X = tra.drop('y', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n",
        "\n",
        "cat = CatBoostRegressor()\n",
        "cat.fit(X_train, y_train)\n",
        "\n",
        "y_pred = cat.predict(X_test)\n",
        "\n",
        "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "tes = pd.get_dummies(tes)\n",
        "\n",
        "pred = cat.predict(tes)\n",
        "\n",
        "sub_pred = pd.DataFrame({\"Order_No\":sub['Order_No'], \n",
        "                           \"Time from Pickup to Arrival\": pred })\n",
        "sub_pred.to_csv(\"111.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}